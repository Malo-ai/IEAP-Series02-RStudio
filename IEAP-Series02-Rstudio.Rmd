---
title: "IEAP-Series02-Rstudio.Rmd"
output: html_notebook
---
### 1. IEAP-Series02-Rstudio

IEAP-2025 Series 02 RStudio Data mining and statistical tests Denis MOTTET 24 September, 2025, 21:28 \# 1 Correlations and linear regression In this series of exercises, you will explore correlations and linear regression, using a dataset from a real experiment.

## 1.1 The problem

There is a relationship between the nonuse of the proximal part of the upper limb (PANU) and the nonuse of the shoulder (SANU) or the elbow (EENU) ? 

## 1.2 The data

Data is far from perfect, but this is the reality of experimental data, especially in the case of clinical data ==> Download the file NonUse.csv from the course Moodle.

```{r load-data echo=FALSE}
nonuse <- read.csv("data/test_data/NonUse.csv", sep=",", header=TRUE)
head(nonuse)
summary(nonuse)
```

| name | description                  | unit | range |
|------|------------------------------|------|-------|
| PANU | Proximal Arm Non Use         | \%   | 0-100 |
| SANU | Shoulder Antepulsion Non Use | \%   | 0-100 |
| EENU | Elbow Extension Non Use      | \%   | 0-100 |

Description of the experiment, variables, and data characteristics  

**Description of the experiment**  
The dataset comes from a clinical experiment conducted with post-stroke patients. The aim is to study nonuse of the upper limb, by quantifying how much patients avoid using certain joints during reaching tasks. 

Three levels of nonuse were measured: 
proximal arm (PANU), 
shoulder antepulsion (SANU) 
and elbow extension (EENU) 
The central question is: is proximal nonuse (PANU) related to nonuse of the shoulder or the elbow?  

**Variables**  
All variables are continuous, expressed as percentages, and computed by comparing performances between two experimental conditions (free trunk vs blocked trunk).  
- PANU (Proximal Arm Non Use): nonuse of the proximal arm segment (upper arm).  
  Unit: % – Theoretical range: 0–100  
- SANU (Shoulder Antepulsion Non Use): nonuse of the shoulder joint in antepulsion.  
  Unit: % – Theoretical range: 0–100  
- EENU (Elbow Extension Non Use): nonuse of the elbow joint in extension.  
  Unit: % – Theoretical range: 0–100  

**Data characteristics**  
Each row corresponds to one participant (post-stroke).  
Columns display the measures for `PANU`, `SANU`, `EENU`.  
Values are real numbers, theoretically between 0 and 100.  
In practice, some results may be negative or greater than 100 due to experimental noise.  
The values for (`EENU`) and (`SANU`) are missing for patients 5 and 6.  


## 1.3 Corelation analysis

Since some values are missing, we use a Spearman correlation to observe whether patients with high PANU tend to have high SANU or EENU, without assuming a normal or linear distribution.

```{r}
cor.test(nonuse$PANU, nonuse$SANU, method="spearman")
```

Spearman correlation revealed a weak but significant positive association between PANU and SANU (ρ = 0.22, p = 0.002), indicating that patients with higher proximal arm nonuse tended to exhibit slightly higher shoulder nonuse.

```{r}
cor.test(nonuse$PANU, nonuse$EENU, method="spearman")
```
Spearman correlation revealed a moderate and highly significant positive association between PANU and EENU (ρ = 0.39, p < 0.001), indicating that patients with higher proximal arm nonuse tended to also exhibit higher elbow nonuse.

Visualize the PANU-SANU relationship and the PANU-EENU relationship

```{r plot sanu}
library(ggplot2)
ggplot(nonuse, aes(x=PANU, y=SANU)) +
  geom_point() +
  xlim(-100, 100) +
  ylim(-100, 100) +
  labs(title="PANU vs SANU", x="PANU (%)", y="SANU (%)") +
  theme_minimal()
```

Perform a linear regression for PANU-SANU (and for PANU-EENU) \*\* we do not predit a linear relationship between the variable, but we do it because it is asked...\*\*

```{r plot sanu}
library(ggplot2)
ggplot(nonuse, aes(x=PANU, y=EENU)) +
  geom_point() +
  geom_smooth(method="lm", se=FALSE, color="blue") +
  #xlim(-100, 100) +
  #ylim(-100, 100) +
  labs(title="PANU vs EENU", x="PANU (%)", y="EENU (%)") +
  theme_minimal()
```

Give the regression equations: PANU = a \* SANU + b and PANU = a \* EENU + b

```{r lm sanu}
lm_sanu <- lm(SANU ~ PANU, data=nonuse)
summary(lm_sanu)
coef(lm_sanu)
slope <- coef(lm_sanu)[2]
intercept <- coef(lm_sanu)[1]
cat("Regression equation: SANU =", slope, "* PANU +", intercept, "\n")
```
Results summarize: 
Linear regression indicated a very weak positive relationship between proximal arm nonuse (PANU) and shoulder nonuse (SANU), but this association was not statistically significant (SANU = 0.089 * PANU + 0.586, p = 0.171, R² = 0.009). Spearman correlation, however, suggested a weak monotone trend (ρ = 0.22, p = 0.002), indicating that patients with higher PANU may slightly tend to have higher SANU.


Limits : 

- Linear regression assumptions: the relationship may be monotone rather than strictly linear, which reduces R².
- Weak association: slope is small, explaining very little variance.
- Missing data: 223 observations were removed, reducing power.
- Outliers: residuals range widely (-40 to 39), which can distort linear estimates.
- Correlation ≠ causation: cannot infer that PANU causes SANU


### 2 Statistical tests: comparison of medians (or means?)

## 2.1 What is a statistical test ? and when to use it ? Below are some questions to guide your analysis. You can answer them in your notebook, with a short sentence for each question.

**Central tendency :**
Median : Central tendency of a distribution of ordinal variables. 50% of the observations are below it and 50% are above it. Intersting point : extreme values do not affect it.
Mean: Central tendency of a distribution of continuous variables. It is the sum of all values divided by the number of values. Intersting point : extreme values affect it.

**Dispersion mesure :**
Variance: Measure of the dispersion of a distribution. It is the mean of the squared differences between each value and the mean of the distribution. Useful to describe the dispersion of a distribution.
Standard deviation: Square root of the variance. It is expressed in the same unit as the variable. Useful to describe the dispersion of a distribution.
Normal distribution: distribution that follows a bell-shaped curve. It is characterized by its mean and standard deviation. Many statistical tests assume that the data follows a normal distribution.

**Statistical test :** all procedures for expressing parameters or studying their behavior in specific situations.
You can use it when you follow this rules : 
1- Hypotheses is clearly define – state null (H₀) and alternative (H₁) hypotheses.
2- You have check assumptions – verify parametric assumptions (normality, variance homogeneity) or use non-parametric tests if violated.
3- Choose the correct test – depending on data type, number of groups, paired/unpaired observations.
4- Decide significance level (α) – commonly 0.05.
5- Avoid multiple testing without correction – control false positives.
6- Interpret p-values correctly – p < α indicates evidence against H₀, not proof.
7- Report effect sizes and confidence intervals – not just p-values.
8- Consider sample size and power – small samples may give unreliable results

**Test :**
Parametric test : statistical test that assumes the data follow a specific distribution, usually normal, and relies on population parameters (mean, variance).
Assumptions of a parametric test:
1- Normality: The data (or residuals) are approximately normally distributed.
2- Independence: Observations are independent of each other.
3- Homogeneity of variance: Variances are equal across groups (for tests comparing groups).
4- Scale of measurement: Data are interval or ratio (continuous).
5- Random sampling: Data are collected through random sampling from the population.
6- Linearity (for correlations/regression): Relationship between variables is linear.

A non-parametric test : statistical test that does not assume a specific distribution for the data and is often used for ordinal data or when parametric assumptions are violated.
What are the assumptions of non-parametric tests : 
1- Independence: Observations are independent of each other.
2- Ordinal or continuous data: Data should be at least ordinal (ranked) or continuous.
3- Similar shape of distributions: For some tests (e.g., Mann-Whitney U), the distributions of the groups should have a similar shape.
4- Random sampling: Data should be collected through random sampling from the population.
5- Sufficient sample size: While non-parametric tests are less sensitive to small sample sizes, very small samples may still limit the test's power.


P-value : probability of obtaining test results at least as extreme as the observed results, assuming that the null hypothesis (H₀) is true. It quantifies the evidence against H₀; a smaller p-value indicates stronger evidence to reject H₀.
Risk of error when using a statistical test : the probability of making a wrong decision based on the test result. The two main types of errors are Type I error (false positive) and Type II error (false negative). The significance level (α) controls the risk of Type I error, while sample size and effect size influence the risk of Type II error.
Difference between a paired and an unpaired test : 
paired test : used when comparing two related or matched groups, such as measurements taken from the same subjects before and after an intervention. It accounts for the dependency between observations.
unpaired test : used when comparing two independent groups, where the observations in one group do not influence or relate to the observations in the other group.

Source : Alain Varray Course, Statistics – Master 1 Common Core – UE3 E1

## 2.2 Effect of treatment over time This is a very classical question in clinical or sport research: does a treatment-training have an effect over time?

This project evaluates the effect of a cardiac rehabilitation program on participant performance.  
Using pre- and post-intervention performance scores, the study applies paired t-tests and visualizations (line plots, boxplots with jitter) to assess improvements. The analysis highlights significant performance gains and illustrates individual responses to the intervention. 

2.2.1 Download the file PrePost.csv

| name | description                  | unit | range |
|------|------------------------------|------|-------|
| PANU | Proximal Arm Non Use         | \%   | 0-100 |
| SANU | Shoulder Antepulsion Non Use | \%   | 0-100 |
| EENU | Elbow Extension Non Use      | \%   | 0-100 |

```{r load-data echo=FALSE}
nonuse <- read.csv("data/test_data/PrePost.csv", sep=",", header=TRUE)
head(nonuse)
summary(nonuse)
```

| Variable \| Description \| Unit \| Possible values \| Expected change \|
|Perf | Performance measure after rehabilitation | score | 125-148 | Increase after intervention |
|Time | Mesuring timing | Before/After | Before, After | After > Before |

```{r}
# Load libraries
library(dplyr)    # Data manipulation
library(tidyr)    # Pivoting
library(ggplot2)  # Plotting
library(readr)    # Read CSV

# Step 1: Load CSV
PrePost <- read.csv("data/test_data/PrePost.csv", sep = ",", header = TRUE)

# Step 2: Convert 'time' to factor (Before/After)
PrePost$time <- factor(PrePost$time, levels = c("Before", "After"))

# Step 3: Add participant ID
PrePost <- PrePost %>%
  group_by(time) %>%
  mutate(id = row_number()) %>%
  ungroup()

# Step 4: Pivot to wide format
PrePost_wide <- PrePost %>%
  pivot_wider(names_from = time, values_from = perf) %>%
  mutate(diff = After - Before)

# Quick check
head(PrePost_wide)
summary(PrePost)

# Step 5: Normality test on differences
shapiro_test <- shapiro.test(PrePost_wide$diff)
print(shapiro_test)

# Step 6: Paired t-test
t_result <- t.test(PrePost_wide$Before, PrePost_wide$After, paired = TRUE)
print(t_result)

# --- Helper function to save ggplot as PNG ---
save_ggplot_png <- function(plot, filename, width=8, height=6, dpi=150) {
  ggsave(filename, plot=plot, width=width, height=height, dpi=dpi)
  print(plot)  # display in notebook
}

# Step 7a: Paired line plot
line_plot <- ggplot(PrePost, aes(x = time, y = perf)) +
  geom_point() +
  geom_line(aes(group = id), color = "blue", alpha = 0.5) +
  stat_summary(fun = mean, geom = "point", color = "red", size = 3) +
  stat_summary(fun = mean, geom = "line", color = "red", size = 1.5) +
  theme_minimal() +
  labs(title = "Effect of Cardiac Rehabilitation on Performance",
       y = "Performance")

# Save and display
save_ggplot_png(line_plot, "Paired_Line_Plot.png")

# Step 7b: Boxplot with jitter
box_plot <- ggplot(PrePost, aes(x = time, y = perf)) +
  geom_boxplot(fill = c("lightblue", "lightgreen")) +
  geom_jitter(width = 0.1, alpha = 0.7) +
  theme_minimal() +
  labs(title = "Performance Before and After Rehabilitation",
       y = "Performance")

# Save and display
save_ggplot_png(box_plot, "Boxplot_Performance.png")
```
# 2.2.2. Analysis

Test used : Paired t-test (parametric) because the differences are normally distributed (Shapiro-Wilk p = 0.20 > 0.05).  

Graph used : Paired line plot and boxplot with jitter because they effectively show individual changes and group distributions. 

Results : 
A paired t-test was conducted to compare performance before and after the cardiac rehabilitation program. There was a significant increase in performance after the intervention, t(7) = -5.40, p = 0.001, with a mean difference of -2.5 (95% CI [-3.59, -1.41]).  

Conclusion : This indicates that the rehabilitation program had a positive effect on participant performance.  

## 2.3 Testing some stereotypes Humans have stereotypes, some of them are probably true, some others are probably false (e.g., ref ).

This project explores potential associations between snoring, body weight, alcohol consumption, smoking habits, and sex. Using a combination of non-parametric tests (Wilcoxon), Chi-squared/Fisher tests, and correlation analysis, it investigates common stereotypes (e.g., “snorers are heavier” or “men smoke more”). Visualizations include boxplots, barplots, and correlation matrices to illustrate relationships between variables.

## 2.3.1 The data Download the file snore.txt

```{r load-data echo=FALSE}
nonuse <- read.csv("data/test_data/snore.txt", sep=",", header=TRUE)
head(nonuse)
summary(nonuse)
```

Answer Question (1,2,3,4,5)

```{r}
# Load libraries
library(dplyr)
library(ggplot2)
library(readr)
library(GGally)

# Step 1: Import data
snore <- read.table("data/test_data/snore.txt", header = TRUE)

# Step 2: Recode categorical variables
snore$sex   <- factor(snore$sex,   levels = c("H","F"), labels = c("Homme","Femme"))
snore$snore <- factor(snore$snore, levels = c("N","O"), labels = c("Non","Oui"))
snore$tabac <- factor(snore$tabac, levels = c("N","O"), labels = c("Non","Oui"))

# Step 3: Convert numeric columns
num_cols <- c("age", "weight", "height", "alcool")
for (col in num_cols) {
  snore[[col]] <- as.numeric(as.character(snore[[col]]))
}

# Step 4: Function to choose t-test or Wilcoxon
run_test_numeric <- function(var, group) {
  tbl <- table(group)
  if (any(tbl < 3)) {
    cat("Group size too small, using Wilcoxon test\n")
    res <- wilcox.test(var ~ group)
  } else {
    normal <- all(sapply(levels(group), function(g) {
      length(var[group==g])>=3 && shapiro.test(var[group==g])$p.value > 0.05
    }))
    if (normal) {
      equal_var <- var.test(var ~ group)$p.value > 0.05
      res <- t.test(var ~ group, var.equal = equal_var)
    } else {
      res <- wilcox.test(var ~ group)
    }
  }
  return(res)
}

# Step 5: Function for categorical test
run_test_categorical <- function(var, group) {
  tab <- table(var, group)
  if (any(chisq.test(tab)$expected < 5)) {
    res <- fisher.test(tab)
  } else {
    res <- chisq.test(tab)
  }
  return(res)
}

# Step 6: Helper to display + save base R plots
display_save_base <- function(plot_expr, filename, width=800, height=600) {
  # Display in notebook
  eval(plot_expr)
  
  # Save to PNG
  png(filename, width=width, height=height)
  eval(plot_expr)
  dev.off()
}

# --- Q1: Weight by snoring ---
cat("\nQ1: Weight by snoring\n")
res1 <- run_test_numeric(snore$weight, snore$snore)
print(res1)
display_save_base(
  quote(boxplot(weight ~ snore, data=snore,
                main="Weight by snoring",
                ylab="Weight (kg)",
                xlab="Snoring")),
  "Weight_by_snoring.png"
)

# --- Q2: Alcohol by snoring ---
cat("\nQ2: Alcohol by snoring\n")
res2 <- run_test_numeric(snore$alcool, snore$snore)
print(res2)
display_save_base(
  quote(boxplot(alcool ~ snore, data=snore,
                main="Alcohol by snoring",
                ylab="Glasses/week",
                xlab="Snoring")),
  "Alcohol_by_snoring.png"
)

# --- Q3: Smoking by snoring ---
cat("\nQ3: Smoking by snoring\n")
res3 <- run_test_categorical(snore$tabac, snore$snore)
print(res3)
display_save_base(
  quote(barplot(table(snore$tabac, snore$snore), beside=TRUE, legend=TRUE,
                main="Smoking by snoring", xlab="Snoring", ylab="Count")),
  "Smoking_by_snoring.png"
)

# --- Q4: Weight by sex ---
cat("\nQ4: Weight by sex\n")
res4 <- run_test_numeric(snore$weight, snore$sex)
print(res4)
display_save_base(
  quote(boxplot(weight ~ sex, data=snore,
                main="Weight by sex",
                ylab="Weight (kg)",
                xlab="Sex")),
  "Weight_by_sex.png"
)

# --- Q5: Smoking by sex ---
cat("\nQ5: Smoking by sex\n")
res5 <- run_test_categorical(snore$tabac, snore$sex)
print(res5)
display_save_base(
  quote(barplot(table(snore$tabac, snore$sex), beside=TRUE, legend=TRUE,
                main="Smoking by sex", xlab="Sex", ylab="Count")),
  "Smoking_by_sex.png"
)

# --- General correlations (numeric variables) ---
num_vars <- snore[, c("age","weight","height","alcool")]
cor_matrix <- cor(num_vars, use="complete.obs", method="spearman")
print(cor_matrix)

# Display + save correlation matrix using GGally
p_corr <- GGally::ggcorr(num_vars, label=TRUE, label_round=2)
print(p_corr)  # Display in notebook
ggsave("Correlation_matrix.png", plot=p_corr, width=8, height=6, dpi=150)

```
# 2.3.3. Analysis

**Q1. Are snorers fatter?**
Test: Wilcoxon rank sum test   
Résultat: W = 1154, p = 0.908 → non significatif    
Conclusion: There is no evidence that snorers are heavier than non-snorers. The data do not confirm this stereotype  

**Q2. Do snorers drink more?**  
Test: Wilcoxon rank sum test  
Résultat: W = 788, p = 0.0086 → significatif  
Conclusion: Snorers tend to consume more alcohol per week than non-snorers. The data support this stereotype.  

**Q3. Do snorers smoke more?**  
Test: Pearson's Chi-squared test  
Résultat: X² = 0.689, p = 0.407 → non significatif  
Conclusion: There is no evidence that snorers smoke more than non-snorers. The data do not confirm this stereotype  

**Q4. Are men fatter?**  
Test: Wilcoxon rank sum test  
Résultat: W = 981.5, p = 0.729 → non significatif  
Conclusion: There is no evidence that men weigh more than women in this sample. The data do not support this stereotype.  

**Q5. Do women smoke less?**  
Test: Pearson's Chi-squared test  
Résultat: X² = 7.002, p = 0.0081 → significatif  
Conclusion: Women smoke significantly less than men. The data confirm this stereotype.  

**Correlations between variables**
Weight and height are highly correlated (0.93), which is expected.
Alcohol consumption shows very weak correlations with other numeric variables.
Age does not correlate meaningfully with weight, height, or alcohol.

**General conclusion :**
Some stereotypes are not supported (weight by snoring, weight by sex, smoking by snoring).
Others are supported (snorers drink more, women smoke less).
Numeric variables mostly show expected anthropometric correlations (weight ↔ height), but alcohol is largely independent.  

# 3. Epilogue

Probably, in complex systems, we can make predictions based on the variability of data at a given time on the evolution of a system. In addition, considering the strength of the relationships allows us to put into perspective which indicator to play on and why for the organization/disorganization of a system. (e.g. sports team, organization of political bodies and declaration of law in France, cellular development, ....).

