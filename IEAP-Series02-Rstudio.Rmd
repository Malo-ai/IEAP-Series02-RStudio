---
title: "IEAP-Series02-Rstudio.Rmd"
output: html_notebook
---
### 1. IEAP-Series02-Rstudio

IEAP-2025 Series 02 RStudio Data mining and statistical tests Denis MOTTET 24 September, 2025, 21:28 \# 1 Correlations and linear regression In this series of exercises, you will explore correlations and linear regression, using a dataset from a real experiment.

## 1.1 The problem

There is a relationship between the nonuse of the proximal part of the upper limb (PANU) and the nonuse of the shoulder (SANU) or the elbow (EENU) ? 

## 1.2 The data

Data is far from perfect, but this is the reality of experimental data, especially in the case of clinical data ==> Download the file NonUse.csv from the course Moodle.

```{r load-data echo=FALSE}
nonuse <- read.csv("data/test_data/NonUse.csv", sep=",", header=TRUE)
head(nonuse)
summary(nonuse)
```

| name | description                  | unit | range |
|------|------------------------------|------|-------|
| PANU | Proximal Arm Non Use         | \%   | 0-100 |
| SANU | Shoulder Antepulsion Non Use | \%   | 0-100 |
| EENU | Elbow Extension Non Use      | \%   | 0-100 |

Description of the experiment, variables, and data characteristics  

**Description of the experiment**  
The dataset comes from a clinical experiment conducted with post-stroke patients. The aim is to study nonuse of the upper limb, by quantifying how much patients avoid using certain joints during reaching tasks. 

Three levels of nonuse were measured: 
proximal arm (PANU), 
shoulder antepulsion (SANU) 
and elbow extension (EENU) 
The central question is: is proximal nonuse (PANU) related to nonuse of the shoulder or the elbow?  

**Variables**  
All variables are continuous, expressed as percentages, and computed by comparing performances between two experimental conditions (free trunk vs blocked trunk).  
- PANU (Proximal Arm Non Use): nonuse of the proximal arm segment (upper arm).  
  Unit: % – Theoretical range: 0–100  
- SANU (Shoulder Antepulsion Non Use): nonuse of the shoulder joint in antepulsion.  
  Unit: % – Theoretical range: 0–100  
- EENU (Elbow Extension Non Use): nonuse of the elbow joint in extension.  
  Unit: % – Theoretical range: 0–100  

**Data characteristics**  
Each row corresponds to one participant (post-stroke).  
Columns display the measures for `PANU`, `SANU`, `EENU`.  
Values are real numbers, theoretically between 0 and 100.  
In practice, some results may be negative or greater than 100 due to experimental noise.  
The values for (`EENU`) and (`SANU`) are missing for patients 5 and 6.  


## 1.3 Corelation analysis

Since some values are missing, we use a Spearman correlation to observe whether patients with high PANU tend to have high SANU or EENU, without assuming a normal or linear distribution.

```{r}
cor.test(nonuse$PANU, nonuse$SANU, method="spearman")
```

Spearman correlation revealed a weak but significant positive association between PANU and SANU (ρ = 0.22, p = 0.002), indicating that patients with higher proximal arm nonuse tended to exhibit slightly higher shoulder nonuse.

```{r}
cor.test(nonuse$PANU, nonuse$EENU, method="spearman")
```
Spearman correlation revealed a moderate and highly significant positive association between PANU and EENU (ρ = 0.39, p < 0.001), indicating that patients with higher proximal arm nonuse tended to also exhibit higher elbow nonuse.

Visualize the PANU-SANU relationship and the PANU-EENU relationship

```{r plot sanu}
library(ggplot2)
ggplot(nonuse, aes(x=PANU, y=SANU)) +
  geom_point() +
  xlim(-100, 100) +
  ylim(-100, 100) +
  labs(title="PANU vs SANU", x="PANU (%)", y="SANU (%)") +
  theme_minimal()
```

Perform a linear regression for PANU-SANU (and for PANU-EENU) \*\* we do not predit a linear relationship between the variable, but we do it because it is asked...\*\*

```{r plot sanu}
library(ggplot2)
ggplot(nonuse, aes(x=PANU, y=EENU)) +
  geom_point() +
  geom_smooth(method="lm", se=FALSE, color="blue") +
  #xlim(-100, 100) +
  #ylim(-100, 100) +
  labs(title="PANU vs EENU", x="PANU (%)", y="EENU (%)") +
  theme_minimal()
```

Give the regression equations: PANU = a \* SANU + b and PANU = a \* EENU + b

```{r lm sanu}
lm_sanu <- lm(SANU ~ PANU, data=nonuse)
summary(lm_sanu)
coef(lm_sanu)
slope <- coef(lm_sanu)[2]
intercept <- coef(lm_sanu)[1]
cat("Regression equation: SANU =", slope, "* PANU +", intercept, "\n")
```
Results summarize: 
Linear regression indicated a very weak positive relationship between proximal arm nonuse (PANU) and shoulder nonuse (SANU), but this association was not statistically significant (SANU = 0.089 * PANU + 0.586, p = 0.171, R² = 0.009). Spearman correlation, however, suggested a weak monotone trend (ρ = 0.22, p = 0.002), indicating that patients with higher PANU may slightly tend to have higher SANU.


Limits : 

- Linear regression assumptions: the relationship may be monotone rather than strictly linear, which reduces R².
- Weak association: slope is small, explaining very little variance.
- Missing data: 223 observations were removed, reducing power.
- Outliers: residuals range widely (-40 to 39), which can distort linear estimates.
- Correlation ≠ causation: cannot infer that PANU causes SANU


### 2 Statistical tests: comparison of medians (or means?)

## 2.1 What is a statistical test ? and when to use it ? Below are some questions to guide your analysis. You can answer them in your notebook, with a short sentence for each question.

**Central tendency :**
Median : Central tendency of a distribution of ordinal variables. 50% of the observations are below it and 50% are above it. Intersting point : extreme values do not affect it.
Mean: Central tendency of a distribution of continuous variables. It is the sum of all values divided by the number of values. Intersting point : extreme values affect it.

**Dispersion mesure :**
Variance: Measure of the dispersion of a distribution. It is the mean of the squared differences between each value and the mean of the distribution. Useful to describe the dispersion of a distribution.
Standard deviation: Square root of the variance. It is expressed in the same unit as the variable. Useful to describe the dispersion of a distribution.
Normal distribution: distribution that follows a bell-shaped curve. It is characterized by its mean and standard deviation. Many statistical tests assume that the data follows a normal distribution.

**Statistical test :** all procedures for expressing parameters or studying their behavior in specific situations.
You can use it when you follow this rules : 
1- Hypotheses is clearly define – state null (H₀) and alternative (H₁) hypotheses.
2- You have check assumptions – verify parametric assumptions (normality, variance homogeneity) or use non-parametric tests if violated.
3- Choose the correct test – depending on data type, number of groups, paired/unpaired observations.
4- Decide significance level (α) – commonly 0.05.
5- Avoid multiple testing without correction – control false positives.
6- Interpret p-values correctly – p < α indicates evidence against H₀, not proof.
7- Report effect sizes and confidence intervals – not just p-values.
8- Consider sample size and power – small samples may give unreliable results

**Test :**
Parametric test : statistical test that assumes the data follow a specific distribution, usually normal, and relies on population parameters (mean, variance).
Assumptions of a parametric test:
1- Normality: The data (or residuals) are approximately normally distributed.
2- Independence: Observations are independent of each other.
3- Homogeneity of variance: Variances are equal across groups (for tests comparing groups).
4- Scale of measurement: Data are interval or ratio (continuous).
5- Random sampling: Data are collected through random sampling from the population.
6- Linearity (for correlations/regression): Relationship between variables is linear.

A non-parametric test : statistical test that does not assume a specific distribution for the data and is often used for ordinal data or when parametric assumptions are violated.
What are the assumptions of non-parametric tests : 
1- Independence: Observations are independent of each other.
2- Ordinal or continuous data: Data should be at least ordinal (ranked) or continuous.
3- Similar shape of distributions: For some tests (e.g., Mann-Whitney U), the distributions of the groups should have a similar shape.
4- Random sampling: Data should be collected through random sampling from the population.
5- Sufficient sample size: While non-parametric tests are less sensitive to small sample sizes, very small samples may still limit the test's power.


P-value : probability of obtaining test results at least as extreme as the observed results, assuming that the null hypothesis (H₀) is true. It quantifies the evidence against H₀; a smaller p-value indicates stronger evidence to reject H₀.
Risk of error when using a statistical test : the probability of making a wrong decision based on the test result. The two main types of errors are Type I error (false positive) and Type II error (false negative). The significance level (α) controls the risk of Type I error, while sample size and effect size influence the risk of Type II error.
Difference between a paired and an unpaired test : 
paired test : used when comparing two related or matched groups, such as measurements taken from the same subjects before and after an intervention. It accounts for the dependency between observations.
unpaired test : used when comparing two independent groups, where the observations in one group do not influence or relate to the observations in the other group.

Source : Alain Varray Course, Statistics – Master 1 Common Core – UE3 E1

## 2.2 Effect of treatment over time This is a very classical question in clinical or sport research: does a treatment-training have an effect over time?


Variable | Description | Unit | Possible values | Expected change |



2.2.1 The data Download the file PrePost.csv

```{r load-data echo=FALSE}
nonuse <- read.csv("data/test_data/PrePost.csv", sep=",", header=TRUE)
head(nonuse)
summary(nonuse)
```
Clear : variables, description, units, possible values, expected changes over rehabilitation. Table, with one row per variable, and the following columns:

| Variable \| Description \| Unit \| Possible values \| Expected change \|
|Perf | Performance measure after rehabilitation | score | 125-148 | Increase after intervention |
|Time | Mesuring timing | Before/After | Before, After | After > Before |

2.2.2 The analysis You want to know if the treatment has an effect on one or more of the measured variables.

```{r}
# Load libraries
library(dplyr)    # Data manipulation
library(tidyr)    # Pivoting
library(ggplot2)  # Plotting
library(readr)    # Read CSV

# Step 1: Read CSV
nonuse <- read.csv("data/test_data/PrePost.csv", sep = ",", header = TRUE)

# Quick check
head(nonuse)
summary(nonuse)

# Step 2: Convert 'time' to factor
nonuse$time <- factor(nonuse$time, levels = c("Before", "After"))

# Step 3: Add participant ID to handle duplicates
nonuse <- nonuse %>%
  group_by(time) %>%
  mutate(id = row_number()) %>%
  ungroup()

# Step 4: Pivot to wide format
diff <- nonuse %>%
  pivot_wider(names_from = time, values_from = perf) %>%
  mutate(diff = After - Before)

diff   # View wide table

# Step 5: Check normality of differences
shapiro_test <- shapiro.test(diff$diff)
shapiro_test

# Step 6: Paired test
if(shapiro_test$p.value > 0.05){
  # Parametric: paired t-test
  test_result <- t.test(diff$After, diff$Before, paired = TRUE)
  test_type <- "Paired t-test"
} else {
  # Non-parametric: Wilcoxon signed-rank test
  test_result <- wilcox.test(diff$After, diff$Before, paired = TRUE)
  test_type <- "Wilcoxon signed-rank test"
}

test_result
cat("Test used:", test_type, "\n")

# --- Step 7a: Paired line plot ---
ggplot(nonuse, aes(x = time, y = perf)) +
  geom_point() +
  geom_line(aes(group = id), color = "blue", alpha = 0.5) +
  stat_summary(fun = mean, geom = "point", color = "red", size = 3) +
  stat_summary(fun = mean, geom = "line", color = "red", size = 1.5) +
  theme_minimal() +
  labs(title = "Effect of Cardiac Rehabilitation on Performance",
       y = "Performance")

# --- Step 7b: Boxplot with jitter ---
ggplot(nonuse, aes(x = time, y = perf)) +
  geom_boxplot(fill = c("lightblue", "lightgreen")) +
  geom_jitter(width = 0.1, alpha = 0.7) +
  theme_minimal() +
  labs(title = "Performance Before and After Rehabilitation",
       y = "Performance")

```
A paired t-test revealed that participants’ performance significantly increased after the cardiac rehabilitation training (Before: M = 136.4, SD = 7.2; After: M = 139.1, SD = 6.8; t(7) = 4.12, p = 0.004), indicating a positive effect of the intervention
, with an average improvement of 2.75 points (95% CI [1.0, 4.5]).

## 2.3 Testing some stereotypes Humans have stereotypes, some of them are probably true, some others are probably false (e.g., ref ).

Here, we will test stereotypes about snorers… among others.

2.3.1 The data Download the file snore.txt

This file contains anthropometric and qualitative measurements (1 person per line).

2.3.2 The analysis Do the data confirm the following stereotypes? Provide a reasoned answer (data, figure, result sentence) for each question. Are snorers fatter? Do snorers drink or smoke more? Are men fatter? Do women smoke less? From a more general perspective: Are there any correlations between variables? 3 Epilogue: beyond the scope of this series Finally, some of you may want to go beyond the scope of this series with new questions, such as:

Can you predict the value of one variable from the others? (linear regression, logistic regression, etc.) Can you classify individuals based on their variables? (clustering, PCA, etc.) NOTE: These questions are more advanced, and I don’t want you to address them from a technical standpoint or provide code. But they give you an idea of what you can do with data mining techniques… provided you know why you want to do it. I invite you to think about the perspective these questions open up and, if you feel ready to do so, to write a short paragraph about it.
